{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "from skmultiflow.data import DataStream\n",
    "from skmultiflow.bayes import NaiveBayes\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "import statistics\n",
    "dataframe=read_csv('Data set (*.csv) path')\n",
    "dim=dataframe.shape\n",
    "array = dataframe.values    \n",
    "Y = array[1:dim[0]-1,dim[1]-1]\n",
    "X = array[1:dim[0]-1,0:dim[1]-1]\n",
    "class_set=np.unique(Y)\n",
    "class_count=np.unique(Y).shape[0] # number of classess\n",
    "chunk_size=5000\n",
    "Percentage=0.1 # percentage of labeled data in each chunk 0.05 or 0.1\n",
    "significance_level=0.98\n",
    "def Unlabeling_data(X_train,Y_train,Percentage,chunk_size,class_count):\n",
    "    labeled_count=round(Percentage*chunk_size)\n",
    "    TLabeled=X_train[0:labeled_count-1]\n",
    "    Y_TLabeled=Y_train[0:labeled_count-1]\n",
    "    X_Unlabeled=X_train[labeled_count:Y_train.shape[0]-1]\n",
    "\n",
    "    cal_count=round(0.3*TLabeled.shape[0])\n",
    "    X_cal=TLabeled[0:cal_count-1]\n",
    "    Y_cal=Y_TLabeled[0:cal_count-1]\n",
    "    X_L=TLabeled[cal_count:TLabeled.shape[0]-1]\n",
    "    Y_L=Y_TLabeled[cal_count:TLabeled.shape[0]-1]\n",
    "\n",
    "    return X_Unlabeled,X_L,Y_L,X_cal,Y_cal\n",
    "\n",
    "def Prediction_by_CP(num,classifier,X,Y,X_Unlabeled,class_count,sl):\n",
    "    row=X_Unlabeled.shape[0]\n",
    "    col=class_count\n",
    "    p_values=np.zeros([row,col])\n",
    "    labels = np.ones((row,col),dtype=bool)\n",
    "    alphas = NCM(num,classifier,X,Y,1,class_count)\n",
    "    for elem in range(row):\n",
    "        c=[]\n",
    "        for o in class_set:\n",
    "            a_test = NCM(num,classifier,np.array([X_Unlabeled[elem,:]]),o,2,class_count)\n",
    "            idx = np.argwhere(Y == o).flatten()\n",
    "            temp=alphas[idx]\n",
    "            p=len(temp[temp>=a_test])\n",
    "            if idx.shape[0]==0:\n",
    "                s=0\n",
    "            else:\n",
    "                s=p/idx.shape[0]\n",
    "            c.append(s)\n",
    "            if s<sl:\n",
    "                labels[elem,int(o)]=False\n",
    "        p_values[elem,:]=np.array(c)\n",
    "    return p_values,labels\n",
    "\n",
    "def NCM(num,classifier,X,Y,t,class_count):\n",
    "    if num==1:\n",
    "        if t==1:\n",
    "            p=np.zeros([X.shape[0],1])\n",
    "            alpha=np.zeros([X.shape[0],1])\n",
    "            for g in range(X.shape[0]):\n",
    "                dic_vote=classifier.get_votes_for_instance(X[g,:])\n",
    "                vote = np.fromiter(dic_vote.values(), dtype=float)\n",
    "                vote_keys = np.fromiter(dic_vote.keys(), dtype=int)\n",
    "                Sum=np.sum(vote)\n",
    "                keys = np.argwhere(vote_keys == int(Y[g])).flatten()\n",
    "                if keys.size == 0:\n",
    "                    p[g]=(1)/(Sum+class_count)\n",
    "                else:\n",
    "                    for key,val in dic_vote.items():  \n",
    "                        if key == float(Y[g]):\n",
    "                            p[g]=(val+1)/(Sum+class_count)\n",
    "                alpha[g]=1-p[g]\n",
    "           \n",
    "        else:\n",
    "\n",
    "            dic_vote=classifier.get_votes_for_instance(X[0,:])\n",
    "            vote = np.fromiter(dic_vote.values(), dtype=float)\n",
    "            vote_keys = np.fromiter(dic_vote.keys(), dtype=int)\n",
    "            Sum=np.sum(vote)\n",
    "            keys = np.argwhere(vote_keys == int(Y)).flatten()\n",
    "            if keys.size == 0:\n",
    "                p=(1)/(Sum+class_count)\n",
    "            else:\n",
    "                for key,val in dic_vote.items():\n",
    "                    if key == float(Y):\n",
    "                        p=(val+1)/(Sum+class_count) \n",
    "            alpha=1-p\n",
    "            \n",
    "    else:\n",
    "        if t==1:\n",
    "            prediction = classifier.predict_proba(X)\n",
    "            P = np.max(prediction, axis=1)\n",
    "            alpha=1-P\n",
    "        elif t==2:\n",
    "            prediction = classifier.predict_proba(X)\n",
    "            P = prediction[0,int(Y)]\n",
    "            alpha=1-P\n",
    "    return alpha\n",
    "        \n",
    "def Informatives_selection(X_Unlabeled,p_values,labels,class_count):\n",
    "    row = X_Unlabeled.shape[0]\n",
    "    X=np.empty([1,X_Unlabeled.shape[1]])\n",
    "    Y=np.empty([1])\n",
    "    for elem in range(row):\n",
    "        l = np.argwhere(labels[elem,:] == True).flatten()\n",
    "        if len(l)==1:\n",
    "            pp=p_values[elem,l]\n",
    "            X=np.append(X,[X_Unlabeled[elem,:]],axis=0)\n",
    "            Y=np.append(Y,[l[0]],axis=0)\n",
    "    Informatives=X[1:X.shape[0],:]\n",
    "    Y_Informatives=Y[1:Y.shape[0]]\n",
    "    return Informatives, Y_Informatives\n",
    "\n",
    "def Appending_informative_to_nextchunk(X_Currentchunk_Labeled,Y_Currentchunk_Labeled,Informatives,Y_Informatives):\n",
    "    X=np.append(X_Currentchunk_Labeled,Informatives,axis=0)\n",
    "    Y=np.append(Y_Currentchunk_Labeled,Y_Informatives,axis=0)\n",
    "    return X,Y\n",
    "\n",
    "################################ Main\n",
    "num=2 #num=1 --> HT() num=2 --> NB()\n",
    "stream=DataStream(X,Y,target_idx=0, n_targets=class_count, cat_features=None, name=None, allow_nan=False)\n",
    "X_chunk1, Y_chunk1 = stream.next_sample(chunk_size)\n",
    "t=round(0.2*X_chunk1.shape[0])\n",
    "X_test=X_chunk1[0:t-1]\n",
    "Y_test=Y_chunk1[0:t-1]\n",
    "X_train=X_chunk1[t:X_chunk1.shape[0]-1]\n",
    "Y_train=Y_chunk1[t:X_chunk1.shape[0]-1]\n",
    "num_samples = X.shape[0]-X_chunk1.shape[0]\n",
    "[X_U1,X_L1,Y_L1,X_cal1,Y_cal1]=Unlabeling_data(X_train,Y_train,Percentage,chunk_size,class_count) \n",
    "\"\"\"\n",
    "Base Classifier selection\n",
    "\"\"\"\n",
    "if num==1:\n",
    "    classifier = HoeffdingTreeClassifier() # num=1\n",
    "    classifier.fit(X_L1,Y_L1,np.unique(Y))\n",
    "    sl=1\n",
    "    a_file = open(\"Kolmogrov-HT.txt\", \"w\")\n",
    "else:\n",
    "    classifier = NaiveBayes() # num=2\n",
    "    classifier.fit(X_L1,Y_L1)\n",
    "    sl=1\n",
    "    a_file = open(\"Kolmogrov-NB.txt\", \"w\") \n",
    "A=[]\n",
    "Y_pred=classifier.predict(X_test)\n",
    "A.append(accuracy_score(Y_test,Y_pred))\n",
    "Kolmogrov=[]\n",
    "n_samples = 0\n",
    "i=1\n",
    "while n_samples < num_samples  and stream.has_more_samples():\n",
    "    p_values,labels = Prediction_by_CP(num,classifier,X_cal1,Y_cal1,X_U1,class_count,sl)   \n",
    "    Informatives, Y_Informatives = Informatives_selection(X_U1,p_values,labels,class_count)\n",
    "    X_Currentchunk, Y_Currentchunk = stream.next_sample(chunk_size)\n",
    "    t=round(0.2*X_Currentchunk.shape[0])\n",
    "    X_test=X_Currentchunk[0:t-1]\n",
    "    Y_test=Y_Currentchunk[0:t-1]\n",
    "    X_train=X_Currentchunk[t:X_Currentchunk.shape[0]-1]\n",
    "    Y_train=Y_Currentchunk[t:X_Currentchunk.shape[0]-1]\n",
    "    [X_U2,X_L2,Y_L2,X_cal2,Y_cal2]=Unlabeling_data(X_train,Y_train,Percentage,chunk_size,class_count)\n",
    "    p_values1,labels1 = Prediction_by_CP(num,classifier,X_cal1,Y_cal1,X_U2,class_count,sl)\n",
    "    if X_Currentchunk.shape[0]>=chunk_size:\n",
    "        kst=[]\n",
    "        class_set=np.unique(Y)\n",
    "        for h in class_set:\n",
    "            val=sp.stats.ks_2samp(p_values[:,int(h)], p_values1[:,int(h)])\n",
    "            kst.append(val[1])\n",
    "        mean_kst=statistics.mean(kst)\n",
    "        Kolmogrov.append(mean_kst)\n",
    "        print(\"chunk\"+str(i)+\" --> \"+str(i+1))\n",
    "        print(\"kolmogorov smirnov:    \"+str(mean_kst))\n",
    "        if mean_kst<0.05:  #if drift\n",
    "            if num==1:\n",
    "                classifier = HoeffdingTreeClassifier()\n",
    "                classifier.fit(X_L2,Y_L2,np.unique(Y))\n",
    "            else:\n",
    "                classifier = NaiveBayes()\n",
    "                classifier.fit(X_L2,Y_L2)\n",
    "            X_L1=X_L2.copy()\n",
    "            Y_L1=Y_L2.copy()\n",
    "        else:  #if no drift\n",
    "            [New_X_Labeled,New_Y_Labeled]=Appending_informative_to_nextchunk(X_L2,Y_L2,Informatives,Y_Informatives)\n",
    "            if num==1:\n",
    "                classifier.partial_fit(New_X_Labeled,New_Y_Labeled,np.unique(Y))\n",
    "            else:\n",
    "                classifier.partial_fit(New_X_Labeled,New_Y_Labeled)\n",
    "            X_L1=New_X_Labeled.copy()\n",
    "            Y_L1=New_Y_Labeled.copy()\n",
    "    else: \n",
    "        [New_X_Labeled,New_Y_Labeled]=Appending_informative_to_nextchunk(X_L2,Y_L2,Informatives,Y_Informatives)\n",
    "        if num==1:\n",
    "            classifier.partial_fit(New_X_Labeled,New_Y_Labeled,np.unique(Y))\n",
    "        else:\n",
    "            classifier.partial_fit(New_X_Labeled,New_Y_Labeled)\n",
    "        X_L1=New_X_Labeled.copy()\n",
    "        Y_L1=New_Y_Labeled.copy()\n",
    "    X_cal1=X_cal2.copy()\n",
    "    Y_cal1=Y_cal2.copy()\n",
    "    X_U1=X_U2.copy()\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "    A.append(accuracy_score(Y_test,Y_pred))\n",
    "    n_samples += chunk_size\n",
    "    i+=1\n",
    "if num==1:\n",
    "    ss_file = open(\"CPSSDS_HT.txt\", \"w\")\n",
    "    np.savetxt(ss_file, np.array(A), fmt='%.4f', delimiter='\\t\\t', newline='\\n')\n",
    "    ss_file.close()\n",
    "else:\n",
    "    ss_file = open(\"CPSSDS_NB.txt\", \"w\")\n",
    "    np.savetxt(ss_file, np.array(A), fmt='%.4f', delimiter='\\t\\t', newline='\\n')\n",
    "    ss_file.close()\n",
    "chunk_count=len(A)\n",
    "rounds=np.empty([1,chunk_count])\n",
    "np.savetxt(a_file, Kolmogrov, fmt='%.200f', delimiter='\\t\\t', newline='\\n')\n",
    "a_file.close()\n",
    "print(np.array(A))\n",
    "Final_acc=np.mean(np.array(A))\n",
    "print(\"****Overall accuracy*****\")\n",
    "print(\"Acc approach:   \"+str(Final_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
